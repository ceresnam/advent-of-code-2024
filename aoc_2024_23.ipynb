{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## AOC 2024/23\n", "### Part 1\n", "\n", "--- Day 23: LAN Party ---\n", "\n", "As The Historians wander around a secure area at Easter Bunny HQ, you come across posters for a LAN party scheduled for today! Maybe you can find it; you connect to a nearby datalink port and download a map of the local network (your puzzle input).\n", "\n", "The network map provides a list of every connection between two computers. For example:\n", "\n", "```\n", "kh-tc\n", "qp-kh\n", "de-cg\n", "ka-co\n", "yn-aq\n", "qp-ub\n", "cg-tb\n", "vc-aq\n", "tb-ka\n", "wh-tc\n", "yn-cg\n", "kh-ub\n", "ta-co\n", "de-co\n", "tc-td\n", "tb-wq\n", "wh-td\n", "ta-ka\n", "td-qp\n", "aq-cg\n", "wq-ub\n", "ub-vc\n", "de-ta\n", "wq-aq\n", "wq-vc\n", "wh-yn\n", "ka-de\n", "kh-ta\n", "co-tc\n", "wh-qp\n", "tb-vc\n", "td-yn\n", "```\n", "\n", "Each line of text in the network map represents a single connection; the line kh-tc represents a connection between the computer named kh and the computer named tc. Connections aren't directional; tc-kh would mean exactly the same thing.\n", "\n", "LAN parties typically involve multiplayer games, so maybe you can locate it by finding groups of connected computers. Start by looking for sets of three computers where each computer in the set is connected to the other two computers.\n", "\n", "In this example, there are 12 such sets of three inter-connected computers:\n", "\n", "```\n", "aq,cg,yn\n", "aq,vc,wq\n", "co,de,ka\n", "co,de,ta\n", "co,ka,ta\n", "de,ka,ta\n", "kh,qp,ub\n", "qp,td,wh\n", "tb,vc,wq\n", "tc,td,wh\n", "td,wh,yn\n", "ub,vc,wq\n", "```\n", "\n", "If the Chief Historian is here, and he's at the LAN party, it would be best to know that right away. You're pretty sure his computer's name starts with t, so consider only sets of three computers where at least one computer's name starts with t. That narrows the list down to 7 sets of three inter-connected computers:\n", "\n", "```\n", "co,de,ta\n", "co,ka,ta\n", "de,ka,ta\n", "qp,td,wh\n", "tb,vc,wq\n", "tc,td,wh\n", "td,wh,yn\n", "```\n", "\n", "Find all the sets of three inter-connected computers. How many contain at least one computer with a name that starts with t?\n", "\n", "To begin, get your puzzle input."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "I'm a skilled python developer, please help go consider various approaches for solving this problem and their pros/cons. I prefer simpler and understandable solutions, easily readable also for other developers. It's ok to generate code with testcases without explanation. I'll ask if I do not understand it. Always wrap test code into a function, to not clutter the global variable namespace."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "For this graph problem, we have a few approaches to consider:\n", "\n", "1. Using NetworkX library:\n", "   - Pros: Built-in functions for finding cliques of size 3\n", "   - Cons: Might be overkill for this simple problem, adds dependency\n", "   \n", "2. Simple set-based approach:\n", "   - Pros: Very readable, straightforward implementation\n", "   - Cons: Might be slightly less efficient for very large graphs\n", "   \n", "3. Adjacency matrix/list approach:\n", "   - Pros: Could be more efficient for larger graphs\n", "   - Cons: More complex implementation\n", "\n", "Would you like me to implement a solution using any of these approaches? I'd personally lean towards the set-based approach since it's simple and the input size seems manageable.\n", "\n", "Here's a test case implementation to get us started:\n", "\n", "```python\n", "def test_find_triangles():\n", "    test_input = \"\"\"\n", "kh-tc\n", "qp-kh\n", "de-cg\n", "ka-co\n", "yn-aq\n", "qp-ub\n", "cg-tb\n", "vc-aq\n", "tb-ka\n", "wh-tc\n", "yn-cg\n", "kh-ub\n", "ta-co\n", "de-co\n", "tc-td\n", "tb-wq\n", "wh-td\n", "ta-ka\n", "td-qp\n", "aq-cg\n", "wq-ub\n", "ub-vc\n", "de-ta\n", "wq-aq\n", "wq-vc\n", "wh-yn\n", "ka-de\n", "kh-ta\n", "co-tc\n", "wh-qp\n", "tb-vc\n", "td-yn\n", "\"\"\".strip()\n", "    \n", "    assert solve_part1(test_input) == 7\n", "\n", "```\n", "\n", "Which approach would you prefer to explore first?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "load full data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "I'll help you load the puzzle input using the `advent-of-code-data` library which is available in the environment:\n", "\n", "```python\n", "from aocd import get_data\n", "data = get_data(day=23, year=2024)\n", "print(f\"Data length: {len(data.splitlines())} lines\")\n", "print(\"\\nFirst few lines:\")\n", "print('\\n'.join(data.splitlines()[:5]))\n", "```\n", "\n", "Would you like to proceed with implementing one of the approaches after we see the actual data size?"]}, {"cell_type": "code", "metadata": {}, "source": ["def parse_input(s: str) -> list[tuple[str, str]]:\n", "    return [edge.split('-') for edge in s.split('\\n')]\n", "\n", "sample_input = parse_input(\"\"\"\n", "kh-tc\n", "qp-kh\n", "de-cg\n", "ka-co\n", "yn-aq\n", "qp-ub\n", "cg-tb\n", "vc-aq\n", "tb-ka\n", "wh-tc\n", "yn-cg\n", "kh-ub\n", "ta-co\n", "de-co\n", "tc-td\n", "tb-wq\n", "wh-td\n", "ta-ka\n", "td-qp\n", "aq-cg\n", "wq-ub\n", "ub-vc\n", "de-ta\n", "wq-aq\n", "wq-vc\n", "wh-yn\n", "ka-de\n", "kh-ta\n", "co-tc\n", "wh-qp\n", "tb-vc\n", "td-yn\n", "\"\"\".strip()\n", ")\n", "sample_input"], "outputs": [{"data": {"text/plain": ["[['kh', 'tc'],\n", " ['qp', 'kh'],\n", " ['de', 'cg'],\n", " ['ka', 'co'],\n", " ['yn', 'aq'],\n", " ['qp', 'ub'],\n", " ['cg', 'tb'],\n", " ['vc', 'aq'],\n", " ['tb', 'ka'],\n", " ['wh', 'tc'],\n", " ['yn', 'cg'],\n", " ['kh', 'ub'],\n", " ['ta', 'co'],\n", " ['de', 'co'],\n", " ['tc', 'td'],\n", " ['tb', 'wq'],\n", " ['wh', 'td'],\n", " ['ta', 'ka'],\n", " ['td', 'qp'],\n", " ['aq', 'cg'],\n", " ['wq', 'ub'],\n", " ['ub', 'vc'],\n", " ['de', 'ta'],\n", " ['wq', 'aq'],\n", " ['wq', 'vc'],\n", " ['wh', 'yn'],\n", " ['ka', 'de'],\n", " ['kh', 'ta'],\n", " ['co', 'tc'],\n", " ['wh', 'qp'],\n", " ['tb', 'vc'],\n", " ['td', 'yn']]"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["full_input = parse_input(get_data(day=23, year=2024))\n", "\n", "print(f\"nodes: {len(set([e[0] for e in full_input] + [e[1] for e in full_input]))}, edges: {len(full_input)}\")"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["nodes: 520, edges: 3380\n"]}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "estimate complexity of finding cliques of size 3 in graph with 520 nodes and 3380 edges"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let's analyze the complexity for different approaches:\n", "\n", "1. Brute force (checking all possible triplets of nodes):\n", "   - O(n\u00b3) where n is number of nodes\n", "   - With 520 nodes: about 140 million combinations (520 choose 3)\n", "   - Each combination needs edge checking\n", "\n", "2. Edge-based approach (for each edge, find common neighbors):\n", "   - O(m * d) where m is number of edges and d is max degree\n", "   - With 3380 edges and avg degree ~13 (3380*2/520)\n", "   - Much better: roughly 3380 * 13 = ~44k operations\n", "\n", "3. NetworkX's algorithm:\n", "   - Uses edge-based approach internally\n", "   - Similar complexity to approach #2\n", "\n", "The edge-based approach would be significantly more efficient than brute force here. Would you like me to elaborate on any of these approaches or proceed with implementation?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "and for the Adjacency matrix/list approach ?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "For the Adjacency matrix/list approaches:\n", "\n", "Adjacency Matrix:\n", "- Space: O(n\u00b2) = 520\u00b2 \u2248 270k elements\n", "- Finding triangles: O(n\u00b3) operations checking matrix cells\n", "- Not really beneficial here due to sparse graph (3380 edges vs possible 135k edges)\n", "\n", "Adjacency List:\n", "- Space: O(m) = 3380 edges\n", "- Finding triangles: O(m * d) similar to edge-based approach\n", "- For each edge (u,v), check intersection of neighbor lists of u and v\n", "- With good hash-based sets, intersection is O(min(d\u2081,d\u2082))\n", "\n", "The Adjacency List approach is essentially equivalent to the edge-based approach in complexity. Would you like to proceed with implementing one of these approaches?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "lets implement the edge-base approach"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "I'll help you implement the edge-based approach. Here's the basic structure:\n", "\n", "```python\n", "from collections import defaultdict\n", "\n", "def build_graph(edges):\n", "    # Create adjacency list using defaultdict\n", "    graph = defaultdict(set)\n", "    for u, v in edges:\n", "        graph[u].add(v)\n", "        graph[v].add(u)\n", "    return graph\n", "\n", "def find_triangles(edges):\n", "    graph = build_graph(edges)\n", "    triangles = set()\n", "    \n", "    # For each edge (u,v), find common neighbors\n", "    for u, v in edges:\n", "        # Find nodes that are neighbors of both u and v\n", "        common = graph[u] & graph[v]\n", "        \n", "        # For each common neighbor, form a triangle\n", "        for w in common:\n", "            # Sort to ensure unique representation\n", "            triangle = tuple(sorted([u, v, w]))\n", "            triangles.add(triangle)\n", "    \n", "    # Filter triangles containing 't' nodes\n", "    return sum(1 for t in triangles if any(node.startswith('t') for node in t))\n", "\n", "def test():\n", "    assert find_triangles(sample_input) == 7\n", "    print(\"Test passed!\")\n", "\n", "test()\n", "```\n", "\n", "Would you like me to explain any part of this implementation, or should we try it with the full input?"]}, {"cell_type": "code", "metadata": {}, "source": ["from collections import defaultdict\n", "\n", "def build_graph(edges):\n", "    # Create adjacency list using defaultdict\n", "    graph = defaultdict(set)\n", "    for u, v in edges:\n", "        graph[u].add(v)\n", "        graph[v].add(u)\n", "    return graph\n", "\n", "def find_triangles(edges):\n", "    graph = build_graph(edges)\n", "    triangles = set()\n", "    \n", "    # For each edge (u,v), find common neighbors\n", "    for u, v in edges:\n", "        # Find nodes that are neighbors of both u and v\n", "        common = graph[u] & graph[v]\n", "        \n", "        # For each common neighbor, form a triangle\n", "        for w in common:\n", "            # Sort to ensure unique representation\n", "            triangle = tuple(sorted([u, v, w]))\n", "            triangles.add(triangle)\n", "    \n", "    # Filter triangles containing 't' nodes\n", "    return sum(1 for t in triangles if any(node.startswith('t') for node in t))\n", "\n", "def test():\n", "    assert find_triangles(sample_input) == 7\n", "    print(\"Test passed!\")\n", "\n", "test()"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Test passed!\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def solve_part1():\n", "    return find_triangles(full_input)\n", "\n", "solve_part1()"], "outputs": [{"data": {"text/plain": ["1240"]}, "metadata": {}, "output_type": "execute_result", "execution_count": null}], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": ["that was correct answer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Part 2\n", "\n", "--- Part Two ---\n", "\n", "There are still way too many results to go through them all. You'll have to find the LAN party another way and go there yourself.\n", "\n", "Since it doesn't seem like any employees are around, you figure they must all be at the LAN party. If that's true, the LAN party will be the largest set of computers that are all connected to each other. That is, for each computer at the LAN party, that computer will have a connection to every other computer at the LAN party.\n", "\n", "In the above example, the largest set of computers that are all connected to each other is made up of co, de, ka, and ta. Each computer in this set has a connection to every other computer in the set:\n", "\n", "```\n", "ka-co\n", "ta-co\n", "de-co\n", "ta-ka\n", "de-ta\n", "ka-de\n", "```\n", "\n", "The LAN party posters say that the password to get into the LAN party is the name of every computer at the LAN party, sorted alphabetically, then joined together with commas. (The people running the LAN party are clearly a bunch of nerds.) In this example, the password would be co,de,ka,ta.\n", "\n", "What is the password to get into the LAN party?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "what algorithms are known for finding maximum clique?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Finding the maximum clique is NP-hard, but there are several well-known algorithms:\n", "\n", "1. Bron-Kerbosch algorithm:\n", "   - Most popular for practical use\n", "   - Recursive backtracking with pivot selection\n", "   - Works well for sparse graphs\n", "   - Has variants with pruning optimizations\n", "\n", "2. Branch and Bound algorithms:\n", "   - Uses upper/lower bounds to prune search space\n", "   - Can be faster for dense graphs\n", "   - More complex implementation\n", "\n", "3. Greedy approximation:\n", "   - Much faster but not guaranteed to find maximum\n", "   - Usually used for very large graphs\n", "   - Can be used to get initial bound for exact algorithms\n", "\n", "Given our graph size (520 nodes, 3380 edges) and that it's relatively sparse, would you like to explore implementing Bron-Kerbosch? It's typically the go-to choice for problems of this scale."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "lets use Bron-Kerbosch, please explain me how it works"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let me explain Bron-Kerbosch algorithm step by step:\n", "\n", "The algorithm maintains three sets:\n", "1. R: the current clique being built\n", "2. P: prospective vertices that could extend the clique\n", "3. X: vertices already processed (used to avoid duplicates)\n", "\n", "Basic algorithm flow:\n", "1. Start with R empty, P containing all vertices, X empty\n", "2. If both P and X are empty, R is a maximal clique - report it\n", "3. For each vertex v in P:\n", "   - Add v to R\n", "   - Create new P' from vertices in P connected to v\n", "   - Create new X' from vertices in X connected to v\n", "   - Recurse with (R \u222a {v}, P', X')\n", "   - Move v from P to X\n", "\n", "The pivoting variant (more efficient) adds:\n", "- Choose a pivot vertex u from P \u222a X\n", "- Only process vertices in P that aren't neighbors of u\n", "\n", "Would you like me to show a small example of how this works on a tiny graph, or should we proceed with implementation?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "show on tiny graph"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Let's use a tiny graph with 4 vertices that form a clique (complete subgraph) plus one extra vertex:\n", "\n", "```\n", "A --- B\n", "|\\   /|\n", "| \\ / |\n", "|  C  |\n", "| / \\ |\n", "|/   \\|\n", "D --- E\n", "```\n", "\n", "Let's walk through it step by step:\n", "\n", "Initial state:\n", "- R = {}  (current clique)\n", "- P = {A,B,C,D,E}  (candidates)\n", "- X = {}  (processed)\n", "\n", "Should I continue with the first few steps of how the algorithm processes this graph? We can follow what happens when we start with vertex A."]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "continue"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Starting with vertex A:\n", "\n", "Step 1: Choose A\n", "- R = {A}  (add A to current clique)\n", "- P = {B,C,D}  (only A's neighbors remain as candidates)\n", "- X = {}  (nothing processed yet)\n", "\n", "Step 2: Choose B from P\n", "- R = {A,B}\n", "- P = {C}  (only common neighbors of A and B)\n", "- X = {}\n", "\n", "Step 3: Choose C from P\n", "- R = {A,B,C}\n", "- P = {}  (no vertices connected to all of A,B,C)\n", "- X = {}\n", "\n", "At this point, we've found a maximal clique {A,B,C}. The algorithm will backtrack and try other paths.\n", "\n", "Would you like me to continue with what happens when we backtrack, or is this clear so far?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "continue"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Okay, let's see what happens when we backtrack:\n", "\n", "After finding {A,B,C}, we backtrack from C:\n", "- Move C to X\n", "- R = {A,B}\n", "- P = {}  (no more candidates with B)\n", "- X = {C}  (C is processed)\n", "\n", "Backtrack from B:\n", "- Move B to X\n", "- R = {A}\n", "- P = {D}  (D is still a candidate from A's neighbors)\n", "- X = {B,C}  (B and C processed)\n", "\n", "Try path with D:\n", "- R = {A,D}\n", "- P = {}  (no vertices connected to both A and D that we haven't tried)\n", "- X = {B,C}\n", "\n", "This finds another maximal clique {A,D}.\n", "\n", "Should I continue with what happens when we backtrack from A completely and start with a new vertex?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "continue"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "Backtrack completely from A:\n", "- Move A to X\n", "- R = {}\n", "- P = {B,C,D,E}  (E wasn't connected to A, so now available)\n", "- X = {A}  (A is processed)\n", "\n", "Start with B:\n", "- R = {B}\n", "- P = {C,E}  (B's unprocessed neighbors)\n", "- X = {A}  (A was processed)\n", "\n", "Try path with C:\n", "- R = {B,C}\n", "- P = {}  (no unprocessed common neighbors)\n", "- X = {A}\n", "\n", "This finds maximal clique {B,C}.\n", "\n", "The algorithm continues this pattern, eventually finding all maximal cliques. In this example, the largest ones are size 3 (like {A,B,C}).\n", "\n", "Would you like to see how the pivoting optimization would work on this same example, or should we move to implementing the algorithm?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Prompt**\n", "\n", "I understand, lets move to implementation"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**AI Response**\n", "\n", "I'll help you implement the Bron-Kerbosch algorithm. Let's start with the basic version first, then we can add pivoting if needed.\n", "\n", "Here's a proposed structure:\n", "\n", "```python\n", "def find_max_clique(edges):\n", "    # Build graph as adjacency sets\n", "    graph = build_graph(edges)  # we already have this from part 1\n", "    \n", "    def bron_kerbosch(R, P, X):\n", "        if not P and not X:\n", "            return R\n", "        \n", "        max_clique = set()\n", "        for v in set(P):  # make copy since we'll modify P\n", "            neighbors = graph[v]\n", "            new_r = R | {v}\n", "            new_p = P & neighbors\n", "            new_x = X & neighbors\n", "            clique = bron_kerbosch(new_r, new_p, new_x)\n", "            if len(clique) > len(max_clique):\n", "                max_clique = clique\n", "            P.remove(v)\n", "            X.add(v)\n", "        return max_clique\n", "\n", "    return bron_kerbosch(set(), set(graph.keys()), set())\n", "\n", "def test_max_clique():\n", "    test_input = \"\"\"\n", "    A-B\n", "    A-C\n", "    A-D\n", "    B-C\n", "    C-D\n", "    B-E\n", "    C-E\n", "    D-E\n", "    \"\"\".strip().split('\\n')\n", "    edges = [edge.strip().split('-') for edge in test_input]\n", "    clique = find_max_clique(edges)\n", "    print(f\"Found max clique: {clique}\")\n", "    assert len(clique) == 3  # should find a clique of size 3\n", "\n", "test_max_clique()\n", "```\n", "\n", "Would you like me to explain any part of this implementation before we try it with our puzzle input?"]}, {"cell_type": "code", "metadata": {}, "source": ["def find_max_clique(edges):\n", "    # Build graph as adjacency sets\n", "    graph = build_graph(edges)  # we already have this from part 1\n", "    \n", "    def bron_kerbosch(R, P, X):\n", "        if not P and not X:\n", "            return R\n", "        \n", "        max_clique = set()\n", "        for v in set(P):  # make copy since we'll modify P\n", "            neighbors = graph[v]\n", "            new_r = R | {v}\n", "            new_p = P & neighbors\n", "            new_x = X & neighbors\n", "            clique = bron_kerbosch(new_r, new_p, new_x)\n", "            if len(clique) > len(max_clique):\n", "                max_clique = clique\n", "            P.remove(v)\n", "            X.add(v)\n", "        return max_clique\n", "\n", "    return bron_kerbosch(set(), set(graph.keys()), set())\n", "\n", "def test_max_clique():\n", "    clique = find_max_clique(sample_input)\n", "    print(f\"Found max clique: {','.join(sorted(clique))}\")\n", "    assert len(clique) == 4  # should find a clique of size 3\n", "\n", "test_max_clique()"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Found max clique: co,de,ka,ta\n"]}], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": ["def solve_part2():\n", "    clique = find_max_clique(full_input)\n", "    print(f\"Found max clique: {','.join(sorted(clique))}\")\n", "\n", "solve_part2()"], "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Found max clique: am,aq,by,ge,gf,ie,mr,mt,rw,sn,te,yi,zb\n"]}], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "python3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 4}